package com.example.backend.common.infrastructure.tokenizer;

import com.example.backend.user.model.User;
import com.example.backend.user.repository.UserRepository;
import com.example.backend.common.exception.ResourceNotFoundException;
import dev.langchain4j.model.openai.OpenAiTokenizer;
import dev.langchain4j.data.message.ChatMessage;
import dev.langchain4j.data.message.AiMessage;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.stereotype.Service;

import java.util.List;

/**
 * ×©×™×¨×•×ª ××¨×›×–×™ ×œ× ×™×”×•×œ ×¦×¨×™×›×ª ×˜×•×§× ×™×
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class TokenUsageService {
    
    private final UserRepository userRepository;
    private final OpenAiTokenizer tokenizer = new OpenAiTokenizer("gpt-4o");
    
    /**
     * ×¢×“×›×Ÿ ×©×™××•×© ×‘×˜×•×§× ×™× ×œ××©×ª××©
     */
    public void addTokenUsage(Long userId, int tokens, String context) {
        try {
            User user = userRepository.findById(userId)
                .orElseThrow(() -> new ResourceNotFoundException("××©×ª××©", userId));
            
            long beforeUsage = user.getTokensUsed();
            user.addTokenUsage(tokens);
            userRepository.save(user);
            
            log.info("ğŸ’° [{}] {} - Added {} tokens. Total: {} / {} ({}%)",
                userId,
                context,
                tokens,
                user.getTokensUsed(),
                user.getTokenQuota(),
                String.format("%.1f", user.getUsagePercentage()));
                
            // ××–×”×¨×” ×× ××ª×§×¨×‘×™× ×œ×’×‘×•×œ
            if (user.getUsagePercentage() >= 80 && beforeUsage < user.getTokenQuota() * 0.8) {
                log.warn("âš ï¸ [{}] User approaching token limit! {}%", 
                    userId, String.format("%.1f", user.getUsagePercentage()));
            }
            
        } catch (Exception e) {
            log.error("âŒ Failed to update token usage for user {}: {}", userId, e.getMessage());
        }
    }
    
    /**
     * ×—×™×©×•×‘ ×˜×•×§× ×™× ××¨×©×™××ª ×”×•×“×¢×•×ª
     */
    public int calculateTokensForMessages(List<ChatMessage> messages) {
        return tokenizer.estimateTokenCountInMessages(messages);
    }
    
    /**
     * ×—×™×©×•×‘ ×˜×•×§× ×™× ××”×•×“×¢×” ×‘×•×“×“×ª
     */
    public int calculateTokensForMessage(AiMessage message) {
        return tokenizer.estimateTokenCountInMessage(message);
    }
    
    /**
     * ×—×™×©×•×‘ ×˜×•×§× ×™× ××˜×§×¡×˜
     */
    public int calculateTokensForText(String text) {
        return tokenizer.estimateTokenCountInText(text);
    }
    
    /**
     * ×‘×“×™×§×” ×× ×™×© ××¡×¤×™×§ ×˜×•×§× ×™×
     */
    public boolean checkTokenQuota(Long userId, int requiredTokens) {
        try {
            User user = userRepository.findById(userId)
                .orElseThrow(() -> new ResourceNotFoundException("××©×ª××©", userId));
            
            return user.hasEnoughTokens(requiredTokens);
            
        } catch (Exception e) {
            log.error("Failed to check token quota", e);
            return true; // ×‘××§×¨×” ×©×œ ×©×’×™××”, ××¤×©×¨ ×œ×”××©×™×š
        }
    }
}
